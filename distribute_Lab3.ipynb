{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3: IMDB Sentiment Classifier\n",
    "\n",
    "**Univ.AI** <br>\n",
    "**DS-1 Cohort 1** <br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![movie_reviews](./images/movie_reviews.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents \n",
    "* [Lab3 IMDB Sentiment Classifier](#Lab3:-Cleaning-and-EDA-on-Goodreads)\n",
    "  * [Overview](##Overview)\n",
    "  * [Part1: Building a Sentiment Classifier using Bag of Words (BOW)](###Part-1-Building-a-Sentiment-Classifier-using-Bag-of-Words-(BOW))\n",
    "    * [1.1 Loading and Splitting data](###1.1-Loading-and-Splitting-the-data)\n",
    "    * [1.2 Preprocessing](###1.2-Preprocessing)\n",
    "    * [1.3 Tokenization](###1.3-Tokenization)\n",
    "    * [1.4 Classification Model](###1.4-Classification-Model)\n",
    "    * [1.5 Prediction and Accuracy](###1.5-Prediction-and-Accuracy)\n",
    "    * [1.6 Confusion Matrix](###1.6-Confusion-Matrix)\n",
    "    * [1.7 Viewing and decoding predictions](###1.7-Viewing-and-decoding-predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In this lab, we will work on building a sentiment classifier. Sentiment classification helps in identifying opinions in text and labelling them (usually positive, negative, neutral) based on the emotions people express within them. We shall work with the **IMDB dataset** where we will try to classify different movie reviews into either a **'positive'** or a **'negative'** category. \n",
    "\n",
    "**Data**:\n",
    "\n",
    "The data from this homework is a small part of the overall data taken from the `Large Movie Review Dataset v1.0`. The data is split evenly with 4k reviews intended for training and 4k for testing your classifier. Moreover, each set has 2k positive and 2k negative reviews. \n",
    "\n",
    "IMDb lets users rate movies on a scale from 1 to 10. To label these reviews the curator of the data labeled anything with ≤ 4 stars as negative and anything with ≥ 7 stars as positive. Reviews with 5 or 6 stars were left out.\n",
    "The original data was compiled by *Andrew Maas* and can be found here: [IMDb Reviews](https://ai.stanford.edu/~amaas/data/sentiment/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the gensim & nltk libraries if not already installed\n",
    "!pip install gensim\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Run this cell to import the libraries required\n",
    "\n",
    "import imdb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "from keras.preprocessing import text\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip the dataset\n",
    "\n",
    "!tar -xzf ./aclImdb.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 : Building a Sentiment Classifier using Bag of Words (BOW)\n",
    "\n",
    "In this part, we will build a **Logistic Regression** model using the **Bag of Words (BOW)** approach. In BOW, every text or document is represented as the bag(multiset) of its words where the frequency of occurrence of each word is used as a feature for training a classifier. Check this [wikipedia link](https://en.wikipedia.org/wiki/Bag-of-words_model#:~:text=The%20bag%2Dof%2Dwords%20model,word%20order%20but%20keeping%20multiplicity.) for more information.\n",
    "\n",
    "Load the IMDB dataset using the helper python script **imdb.py**. This has already been imported at the beginning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.1 Loading and Splitting data**\n",
    "\n",
    "Load the data-set and split into train and test. Print out the shape of your train and test features and labels. ('X_train','X_test','y_train','y_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and split the data using the imdb.py helper python script. This has been already been imported for you\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2 Preprocessing**\n",
    "\n",
    "Clean the reviews by completing the following function. Follow the instructions as mentioned in the comments. Call this function to obtain a list of cleaned train and test reviews.\n",
    "\n",
    "*Hint* - Use [**re.sub**](https://docs.python.org/3/library/re.html) to replace regular expressions or regex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to perform stemming\n",
    "\n",
    "def stemming(text):\n",
    "    \n",
    "    # stems each word in the review to it's root word\n",
    "    stemmer = nltk.porter.PorterStemmer()\n",
    "    text = ' '.join([stemmer.stem(word) for word in text.split()])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_review(text):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function\n",
    "    --------\n",
    "    preprocess_review\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    text: the review which need to be pre-processed\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    clean_review: the pre-processed review obtained after performing the below instructions in the Notes\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    \n",
    "    1. Remove html tags from the text\n",
    "    2. Change all reviews to lowercase\n",
    "    3. Remove special characters - remove everything that is not a letter or a space (use re.sub to replace regex pattern by single \n",
    "       space. The regex pattern for removal of special characters is '[^a-z\\s]+')\n",
    "    4. Remove extra(multiple) spaces (use re.sub to replace regex pattern by single space. The regex pattern for removal of multiple \n",
    "       spaces is '\\s+')\n",
    "    5. Perform stemming, which converts(stems) the word to its base form (for eg: running, runs to run)\n",
    "    \"\"\"\n",
    "    \n",
    "    # your code here\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the preprocess_review function to obtain list of the cleaned reviews\n",
    "\n",
    "X_train_cleaned = [preprocess_review(review) for review in X_train]\n",
    "print('Training data cleaned')\n",
    "X_test_cleaned = [preprocess_review(review) for review in X_test]\n",
    "print('Test data cleaned')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out an example of how a cleaned text looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_cleaned[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.3 Tokenization**\n",
    "\n",
    "Encode the cleaned reviews into integers which can be used by as features in our classification model. This is also called as **tokenization**. We will use the [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) method from the *sklearn* library with a maximum vocabulary size of 1000 and remove stopwords. *Stopwords* are commonly occuring words in English - like *and,i,for,us,the etc*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = CountVectorizer(max_features = 1000, stop_words = 'english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fit the tokenizer to our cleaned training set and store the train & test tokenized data to these variables respectively: **X_train_tokenized** and **X_test_tokenized**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape of the tokenized features for train & test data\n",
    "print(X_train_tokenized.shape,X_test_tokenized.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do you think removing stop-words is important?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a slight fault in the way we have pre-processed and then tokenized data. Can you spot the fault?\n",
    "\n",
    "*Hint: The fault lies in the sequence of operations done* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the top 10 most occuring words in the training set along with their frequency. Note that `tokenizer.vocabulary_` will only give you the index of the word in the vocab; not the count itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.4 Classification model**\n",
    "\n",
    "Use a *Logistic Regression* model for classification with the tokenized reviews as features. Fine-tune your model to find the best value of the hyper-parameter 'C' from the follwing values: *'{0.001,0.01,0.1,1,10,100}'*. Store the final model in the variable *'bow_model'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.5 Prediction and Accuracy**\n",
    "\n",
    "Print the accuracy of your model on both the train and test data-set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.6 Confusion Matrix**\n",
    "\n",
    "Plot the confusion matrix (2x2 matrix of your actual vs predicted values) for both train and test data. Complete the function below which will help you with this. You can use the [confusion matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) from `sklearn` and the [heatmap](https://seaborn.pydata.org/generated/seaborn.heatmap.html) from the `seaborn` library to help with this. They have already been imported at the start of this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot confusion matrix\n",
    "\n",
    "def plot_confusion_matrix(model, validation_features, validation_labels):\n",
    "     \n",
    "    \"\"\"\n",
    "    Function\n",
    "    --------\n",
    "    plot_confusion_matrix\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    model: the classification model\n",
    "    validation_features: features/variables used in the model (X)\n",
    "    validation_labels: response variable (good/bad sentiment) (y)\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    Calling this function should plot a confusion matrix. Use heatmap from the seaborn library\n",
    "    \"\"\"\n",
    "    \n",
    "    # Predict the values from the validation dataset\n",
    "    y_pred = _______\n",
    "    \n",
    "    # Convert validation observations to one hot vectors\n",
    "    y_true = _______\n",
    "    \n",
    "    # compute the confusion matrix\n",
    "    confusion_mtx = _______ \n",
    "\n",
    "    df_cm = pd.DataFrame(confusion_mtx, range(2),\n",
    "                      range(2))\n",
    "    sns.heatmap(df_cm, annot=True, annot_kws = {'size':15}, cmap = 'Blues',fmt = 'd',\n",
    "                norm=LogNorm(df_cm.values.min(),df_cm.values.max()),\n",
    "                cbar_kws={\"ticks\":[0,1,10,1e2,1e3,1e4]},vmin=0.001, vmax=10000)\n",
    "    plt.tight_layout()\n",
    "    plt.title('Confusion matrix')\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.ylim(2,0)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the confusion matrix plots for train data\n",
    "\n",
    "plot_confusion_matrix(bow_model, X_train_tokenized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the confusion matrix plots for test data\n",
    "\n",
    "plot_confusion_matrix(bow_model, X_test_tokenized, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.7 Viewing and decoding predictions**\n",
    "\n",
    "Let's look at the test data for a few cases for the False Positives and False Negatives and see where we are going wrong with the Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = bow_model.predict(X_test_tokenized)\n",
    "df_test = pd.DataFrame(list(zip(X_test, y_pred, y_test)), columns = ['X_test', 'y_pred', 'y_test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create 2 subset dataframes from **df_test** : **df_fp** for all False Positives and **df_fn** for all False Negatives "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# False Positives\n",
    "df_fp = df_test[(df_test['y_pred']==1) & (df_test['y_test']==0)]\n",
    "\n",
    "# False Negatives\n",
    "df_fn = df_test[(df_test['y_pred']==0) & (df_test['y_test']==1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a function to find out the words which contribute most to a particular review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes in the input of the tokenized_review and returns the important words occuring in the review \n",
    "# (according to the tokenizer vocab) along with their frequency\n",
    "\n",
    "def imp_words(tokenized_review):\n",
    "    sum_words = X_train_tokenized.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in tokenizer.vocabulary_.items()]\n",
    "    words_freq = dict(sorted(words_freq, key = lambda x: x[1], reverse=True))\n",
    "\n",
    "    imp_words = []\n",
    "    for x, val in enumerate(tokenized_review):\n",
    "        if val >= 1:\n",
    "            for word, index in tokenizer.vocabulary_.items():\n",
    "                if index == x:\n",
    "                    imp_words.append((word, words_freq[word]))\n",
    "    \n",
    "    return sorted(imp_words, key = lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pick one of the False Positive cases from the `df_fp` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to see an example of a FP review\n",
    "df_fp['X_test'][2001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function 'imp_words' to find out the important occuring words in the review\n",
    "imp_words(X_test_tokenized.toarray()[2001])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you observe? Why do you think this was classified as a False Positive?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the same analysis for one of the False Negatives from the `df_fn` dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to see an example of a FN review\n",
    "df_fn['X_test'][51]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the *important words* in this review which contribute to the classification. Why do you think this was classified as a False Negative?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
